{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '\\ufeff1912'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-99ff94a62447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'food_access_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '\\ufeff1912'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.loadtxt(fname='food_access_data.csv', delimiter=',')\n",
    "#the error message says that I can't import my csv file as numpy because it's reading \"1912\" as a string\n",
    "#I'm not sure why this happened since it's actually an integer, but I moved on based on the solution I saw on the forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = pd.read_csv('food_access_data.csv')\n",
    "#the past 2 commands import my csv file as pandas instead of numpy and names it \"tmp_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tmp_data.to_numpy()\n",
    "#this converts the temporary data \"tmp_data\" from pandas to numpy and names that \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.170e+03 7.430e+02 1.820e+01 ... 5.000e+00 5.500e+01 7.500e+01]\n",
      " [3.373e+03 1.256e+03 1.910e+01 ... 1.100e+01 1.170e+02 8.700e+01]\n",
      " [4.386e+03 1.722e+03 3.300e+00 ... 1.100e+01 7.400e+01 8.500e+01]\n",
      " ...\n",
      " [2.542e+03 1.021e+03 1.270e+01 ... 2.600e+01 1.820e+02 4.070e+02]\n",
      " [3.314e+03 1.322e+03 9.200e+00 ... 4.700e+01 6.200e+01 9.100e+01]\n",
      " [3.894e+03 1.699e+03 1.500e+01 ... 4.400e+01 1.260e+02 1.250e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "#I printed the data to make sure that it corresponds to my csv file\n",
    "#It cut out the first row of data, but there is plenty more data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2170. 3373. 4386. ... 2542. 3314. 3894.]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:,0])\n",
    "#this isolates the first column of the dataset (which corresponds to the population size) and prints it\n",
    "#the first 0 corresponds to row 1, the : corresponds to the last row, and the second 0 corresponds to the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = data[0:,0]\n",
    "#this names the first column of my dataset \"population_size\" so that future analysis is easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2170. 3373. 4386. ... 2542. 3314. 3894.]\n"
     ]
    }
   ],
   "source": [
    "print(population_size)\n",
    "#this prints the variable to make sure that the correct information is saved under this name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following commands name the remaining columns:\n",
    "housing_unit = data[0:,1]\n",
    "#Occupied housing unit count from 2010 census\n",
    "poverty_rate = data[0:,2]\n",
    "#Share of the tract population living with income at or below the Federal poverty thresholds for family size\n",
    "white_half = data[0:,5]\n",
    "#White population count beyond 1/2 mile from supermarket\n",
    "black_half = data[0:,6]\n",
    "#Black or African American population count beyond 1/2 mile from supermarket\n",
    "asian_half = data[0:,7]\n",
    "#Asian population count beyond 1/2 mile from supermarket\n",
    "pac_isl_half = data[0:,8]\n",
    "#Native Hawaiian or Other Pacific Islander population count beyond 1/2 mile from supermarket\n",
    "nat_amer_half = data[0:,9]\n",
    "#American Indian or Alaska Native population count beyond 1/2 mile from supermarket\n",
    "other_half = data[0:,10]\n",
    "#Other/Multiple race population count beyond 1/2 mile from supermarket\n",
    "latino_half = data[0:,11]\n",
    "#Hispanic or Latino ethnicity population count beyond 1/2 mile from supermarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 34.58790941  76.4086176   61.43777905 ... 146.8707357   76.88022638\n",
      "  96.26057867]\n"
     ]
    }
   ],
   "source": [
    "print(latino_half)\n",
    "#spot-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naming the next set of columns\n",
    "white_1 = data[0:,15]\n",
    "#White population count beyond 1 mile from supermarket\n",
    "black_1 = data[0:,16]\n",
    "#Black or African American population count beyond 1 mile from supermarket\n",
    "asian_1 = data[0:,17]\n",
    "#Asian population count beyond 1 mile from supermarket\n",
    "pac_isl_1 = data[0:,18]\n",
    "#Native Hawaiian or Other Pacific Islander population count beyond 1 mile from supermarket\n",
    "nat_ame_1 = data[0:,19]\n",
    "#American Indian or Alaska Native population count beyond 1 mile from supermarket\n",
    "other_1 = data[0:,20]\n",
    "#Other/Multiple race population count beyond 1 mile from supermarket\n",
    "latino_1 = data[0:,21]\n",
    "#Hispanic or Latino ethnicity population count beyond 1 mile from supermarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.17358974 31.22826762 29.85953993 ... 11.64341596 66.77413435\n",
      " 69.21853762]\n"
     ]
    }
   ],
   "source": [
    "print(latino_1)\n",
    "#spot-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naming the next set of variables\n",
    "white_10 = data[0:,25]\n",
    "#White population count beyond 10 miles from supermarket\n",
    "black_10 = data[0:,26]\n",
    "#Black or African American population count beyond 10 miles from supermarket\n",
    "asian_10 = data[0:,27]\n",
    "#Asian population count beyond 10 miles from supermarket\n",
    "pac_isl_10 = data[0:,28]\n",
    "#Native Hawaiian or Other Pacific Islander population count beyond 10 miles from supermarket\n",
    "nat_ame_10 = data[0:,29]\n",
    "#American Indian or Alaska Native population count beyond 10 miles from supermarket\n",
    "other_10 = data[0:,30]\n",
    "#Other/Multiple race population count beyond 10 miles from supermarket\n",
    "latino_10 = data[0:,31]\n",
    "#Hispanic or Latino ethnicity population count beyond 10 miles from supermarket\n",
    "white_total = data[0:,34]\n",
    "#Total count of White population in tract \n",
    "black_total = data[0:,35]\n",
    "#Total count of Black or African American population in tract \n",
    "asian_total = data[0:,36]\n",
    "#Total count of Asian population in tract\n",
    "pac_isl_total = data[0:,37]\n",
    "#Total count of Native Hawaiian and Other Pacific Islander population in tract\n",
    "nat_ame_total = data[0:,38]\n",
    "#Total count of American Indian and Alaska Native population in tract\n",
    "other_total = data[0:,39]\n",
    "#Total count of Other/Multiple race population in tract\n",
    "latino_total = data[0:,40]\n",
    "#Total count of Hispanic or Latino population in tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         ...  0.         17.00000007\n",
      "  0.        ]\n",
      "[ 75.  87.  85. ... 407.  91. 125.]\n"
     ]
    }
   ],
   "source": [
    "print(latino_10)\n",
    "print(latino_total)\n",
    "#spot-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2274.2177485265534"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.average(white_half)\n",
    "#calculate the average White population count beyond 1/2 mile from supermarket per census tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165706327.81089026\n",
      "223551643.0\n"
     ]
    }
   ],
   "source": [
    "white_half_sum = numpy.sum(white_half)\n",
    "#sum of White population count beyond 1/2 mile from supermarket named accordingly\n",
    "print(white_half_sum)\n",
    "white_total_sum = numpy.sum(white_total)\n",
    "print(white_total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.12440614936132\n"
     ]
    }
   ],
   "source": [
    "white_half_percent = white_half_sum/white_total_sum*100\n",
    "print(white_half_percent)\n",
    "#used python as a calculator\n",
    "#percentage of white population that lives beyond 1/2 mile from supermarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.12440614936132"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can also calculate in this way:\n",
    "numpy.sum(white_half)/numpy.sum(white_total)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.60465100795061\n",
      "54.04495715568467\n",
      "61.07425688760808\n",
      "73.63924134804552\n",
      "55.182529892345144\n",
      "54.90252374672336\n"
     ]
    }
   ],
   "source": [
    "black_half_percent = numpy.sum(black_half)/numpy.sum(black_total)*100\n",
    "print(black_half_percent)\n",
    "asian_half_percent = numpy.sum(asian_half)/numpy.sum(asian_total)*100\n",
    "print(asian_half_percent)\n",
    "pac_isl_half_percent = numpy.sum(pac_isl_half)/numpy.sum(pac_isl_total)*100\n",
    "print(pac_isl_half_percent)\n",
    "nat_ame_half_percent = numpy.sum(nat_ame_half)/numpy.sum(nat_ame_total)*100\n",
    "print(nat_ame_half_percent)\n",
    "other_half_percent = numpy.sum(other_half)/numpy.sum(other_total)*100\n",
    "print(other_half_percent)\n",
    "latino_half_percent = numpy.sum(latino_half)/numpy.sum(latino_total)*100\n",
    "print(latino_half_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9291879670927565\n",
      "0.8718103068396604\n",
      "0.15660041866430163\n",
      "0.9084163444392266\n",
      "11.54638916089467\n",
      "0.8525437845488179\n",
      "0.7738845687701836\n"
     ]
    }
   ],
   "source": [
    "white_10_percent = numpy.sum(white_10)/numpy.sum(white_total)*100\n",
    "print(white_10_percent)\n",
    "black_10_percent = numpy.sum(black_10)/numpy.sum(black_total)*100\n",
    "print(black_10_percent)\n",
    "asian_10_percent = numpy.sum(asian_10)/numpy.sum(asian_total)*100\n",
    "print(asian_10_percent)\n",
    "pac_isl_10_percent = numpy.sum(pac_isl_10)/numpy.sum(pac_isl_total)*100\n",
    "print(pac_isl_10_percent)\n",
    "nat_ame_10_percent = numpy.sum(nat_ame_10)/numpy.sum(nat_ame_total)*100\n",
    "print(nat_ame_10_percent)\n",
    "other_10_percent = numpy.sum(other_10)/numpy.sum(other_total)*100\n",
    "print(other_10_percent)\n",
    "latino_10_percent = numpy.sum(latino_10)/numpy.sum(latino_total)*100\n",
    "print(latino_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28477.0001"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.max(white_half)\n",
    "#this gives me the maximum value for the White population count beyond 1/2 mile from supermarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.min(white_half)\n",
    "#this gives me the minimum value for the White population count beyond 1/2 mile from supermarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1820.942381338809"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.std(white_half)\n",
    "#this gives me the standard deviation for the White population count beyond 1/2 mile from supermarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
